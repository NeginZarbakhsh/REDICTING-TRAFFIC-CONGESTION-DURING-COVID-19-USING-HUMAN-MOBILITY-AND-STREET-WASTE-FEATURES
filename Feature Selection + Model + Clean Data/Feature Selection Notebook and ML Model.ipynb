{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c25a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import holidays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "random.seed(44)\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import lightgbm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ec3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots    \n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style('ticks')\n",
    "sns.color_palette(\"Paired\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc40f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading file and date indeing\n",
    "df = pd.read_csv('../Final Data/Agreegated_Data.csv', parse_dates=['date'], index_col= 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0bfee8",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2954ad",
   "metadata": {},
   "source": [
    "### A ) Adding Time-related Features & Holidays in Ireland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcde745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "\n",
    "#Create Time-Related Features\n",
    "df['Month'] = df.date.dt.month\n",
    "df['Year'] = df.date.dt.year\n",
    "df['Day'] = df.date.dt.day_of_week\n",
    "df['Season'] = df['Month'].apply(lambda month_number: (month_number%12 + 3)//3)\n",
    "df = df.set_index(df.date, drop =True)\n",
    "df.drop(['date', 'Month'], inplace = True, axis = 1)\n",
    "df['Holiday'] = pd.Series(df.index).apply(lambda x: holidays.CountryHoliday('Ireland').get(x)).values\n",
    "df['Holiday'] = df['Holiday'].astype('bool').astype('int')\n",
    "\n",
    "# We slected cotegoric features for one-hot encoding\n",
    "df= pd.get_dummies(df, columns=['Holiday', 'Season', 'Day'])\n",
    "df = df.drop('Year', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da0e67",
   "metadata": {},
   "source": [
    "### B) Adding Historical Data of Traffic Congestion in Dublin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f562db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add windowed columns (Features with Lags)\n",
    "for i in range(WINDOW_SIZE):\n",
    "    df[f\"Congestion+{i+1}\"] = df[\"congestion\"].shift(periods=i+1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d077cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect missing values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Period\n",
    "print ('Period of study %', - (df.index.min()- df.index.max()))\n",
    "df.index.min(), df.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8984f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metric Formulation\n",
    "\n",
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100\n",
    "\n",
    "def show_scores(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores = {'R-squared': r2_score(y_test,y_pred)*100,\n",
    "              'MSE':  mean_squared_error(y_test,y_pred),\n",
    "              'RMSE': np.sqrt(mean_squared_error(y_test,y_pred)),\n",
    "              'MAE': mean_absolute_error (y_test,y_pred),\n",
    "              'MAPE': mape (y_test,y_pred)}\n",
    "    return scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff50c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of Train & Test Split (Start & End for zooming)\n",
    "def plot_split (timesteps, values, format = \".\", start = 0 , end = None, color =None, label =None):   \n",
    "\n",
    "    plt.plot(timesteps[start:end], values[start:end],format, color = color, label=label)\n",
    "    \n",
    "    plt.ylabel(\"Traffic congestion (%)\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Feature importance\n",
    "def plot_features (columns, importances, n=43):\n",
    "    df = (pd.DataFrame({\"features\": columns,\n",
    "                      \"feature_importances\": importances})\n",
    "          .sort_values(\"feature_importances\", ascending = False)\n",
    "          .reset_index(drop = True))\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(figsize=[7,43])\n",
    "\n",
    "    ax.barh(df[\"features\"][:n],\n",
    "           df[\"feature_importances\"][:n], color ='seagreen' )\n",
    "    ax.set_ylabel (\"Features\")\n",
    "    ax.set_xlabel(\"Features importance RF\")\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    fig.savefig('rfeatureimportance.pdf',\n",
    "            format='pdf',\n",
    "            dpi=1800,\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c17cf6",
   "metadata": {},
   "source": [
    "## All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 1 # predict next one day\n",
    "WINDOW_SIZE = 1 # use the past week street waste data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c4b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make features and labels\n",
    "X = df.dropna().drop(\"congestion\", axis=1)\n",
    "y = df.dropna()[\"congestion\"]\n",
    "\n",
    "# Make train and test sets\n",
    "split_size = int(len(X) * 0.8)\n",
    "X_train, y_train = X[:split_size], y[:split_size]\n",
    "X_test, y_test = X[split_size:], y[split_size:]\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,5))\n",
    "plot_split(timesteps=X_train.index, values=y_train,  color =\"#f58231\",  label = 'Train date')\n",
    "plot_split(timesteps=X_test.index, values=y_test,  color =\"#911eb4\",  label = 'Test date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150595f",
   "metadata": {},
   "source": [
    "# Feature Selection Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced09dd",
   "metadata": {},
   "source": [
    "## A) Random Forest Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0ac01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Hyperparameter\n",
    "rf_grid = {'n_estimators': np.arange (10,100,10) ,\n",
    "    'max_depth':[None, 3, 5, 10],\n",
    "    'min_samples_split':np.arange (2,20, 2),\n",
    "    'min_samples_leaf':np.arange (1,20, 2),\n",
    "    'max_features':['auto', \"sqrt\", 0.5, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf47f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Nested cross validatio to only split based on train and test and not using validation set as data is not enough\n",
    "tuned_rf =RandomizedSearchCV(RandomForestRegressor(n_jobs=-1,random_state=42),\n",
    "                             param_distributions= rf_grid,\n",
    "                             cv = 5,\n",
    "                             n_iter = 20,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             verbose= True)\n",
    "tuned_rf.fit(X_train, y_train)                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a67c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Best Hyoerparameters\n",
    "tuned_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606df0e8",
   "metadata": {},
   "source": [
    "### Best HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd882ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ideal_rf = RandomForestRegressor (n_estimators= 80, min_samples_split= 2,\n",
    "                                  min_samples_leaf= 1, max_features= 'auto',\n",
    "                                  max_depth= 5,\n",
    "                                  n_jobs = -1)\n",
    "ideal_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(ideal_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec576809",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(X_train.columns,ideal_rf.feature_importances_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores = ideal_rf.feature_importances_\n",
    "rf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b47df",
   "metadata": {},
   "source": [
    "Mutual INFO:\n",
    "Estimate mutual information for a discrete target variable.\n",
    "Mutual information (MI)between two random variables is a non-negative\n",
    "value, which measures the dependency between the variables. It is equal\n",
    "to zero if and only if two random variables are independent, and higher\n",
    "values mean higher dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_scores = mutual_info_classif(X_train,y_train)\n",
    "feature_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c093980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain=pd.DataFrame({'Mutual Info.':i_scores,'RF Score':rf_scores,'Feature':feature_names})\n",
    "df_gain.set_index('Feature', inplace = True)\n",
    "df_gain.sort_values('Mutual Info.', inplace = True, ascending = False)\n",
    "df_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21191e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_gain.index)\n",
    "rr = range(0,n)\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax2 = ax.twinx()\n",
    "ax.bar(df_gain.index, df_gain[\"RF Score\"], label='RF Score',width=.35, color = 'g')\n",
    "\n",
    "ax2.set_xticks(rr)\n",
    "ax2.plot(df_gain.index, df_gain[\"Mutual Info.\"], label='I-Gain', color = 'navy')\n",
    "\n",
    "ax.set_xticklabels(list(df_gain.index), rotation = 90)\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('I-Gain')\n",
    "ax2.set_ylabel('RF Score')\n",
    "fig.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22b82e",
   "metadata": {},
   "source": [
    "## B) LightGBM Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = lightgbm.LGBMRegressor(n_jobs=-1, random_state=42)\n",
    "lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fac0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search CV\n",
    "parameters = {'max_depth'     : [6,7,8,9,10,11,12,13,14,15],\n",
    "              'learning_rate' : [0.01, 0.05, 0.1],\n",
    "              'num_iteration' : [1000, 5000, 10000],\n",
    "              'n_estimators'  : [100,300,500]\n",
    "              # Add more parameters here for tuning\n",
    "              }        \n",
    "tuned_lgb = RandomizedSearchCV(lg,  param_distributions = parameters, cv = 5, \n",
    "                    verbose = 1, n_jobs = -1, refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40050ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_lgb.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_lgb.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tuned_lgb =  lightgbm.LGBMRegressor(n_estimators = 300,max_depth= 12,\n",
    "                                    learning_rate= 0.01,\n",
    "                                    num_iteration= 1000 ,\n",
    "                                    n_jobs = -1)\n",
    "tuned_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(tuned_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2509078",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_lgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(X_train.columns,tuned_lgb.feature_importances_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156a5a58",
   "metadata": {},
   "source": [
    "## C) Pearson Correlation Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11267988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pearson Correlation : Degree in which variables move together\n",
    "def Correlation(data):\n",
    "    mask2 = np.zeros_like(data.corr()) # Making the arrays of zeros\n",
    "    trinangle_indices = np.triu_indices_from(mask2) # triangle of top arrays\n",
    "    mask2[trinangle_indices] = True # make top triangle 1 and below zero\n",
    "\n",
    "    cbar_kws = {\"shrink\":.8,\n",
    "       'extend':'max',\n",
    "       'extendfrac':.2, \n",
    "       \"drawedges\":False,\n",
    "        'label':'Correlation'}\n",
    "    #plt.figure (figsize = (35,1))\n",
    "    fig , ax = plt.subplots(figsize = (7,5))\n",
    "    sns.heatmap(data.corr(), mask = mask2, annot = True, linewidths= 0.5, fmt = '.1f', cmap = 'YlGnBu',annot_kws={'size':14}, cbar_kws=cbar_kws) #annot: values on it\n",
    "\n",
    "    #increasing fonts\n",
    "    plt.xticks (fontsize = 14)\n",
    "    plt.yticks (fontsize = 14)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d052b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df.corr())[\"congestion\"][abs(df.corr()[\"congestion\"])> 0.50].drop('congestion').index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb30c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d3b85",
   "metadata": {},
   "source": [
    "## D) Lasso Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make features and labels\n",
    "X = df.dropna().drop(\"congestion\", axis=1)\n",
    "y = df.dropna()[\"congestion\"]\n",
    "\n",
    "# Make train and test sets\n",
    "split_size = int(len(X) * 0.8)\n",
    "X_train, y_train = X[:split_size], y[:split_size]\n",
    "X_test, y_test = X[split_size:], y[split_size:]\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Model Benifits with feature Scaling for LASSO\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ded3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_ = SelectFromModel(Lasso(alpha=0.005,random_state=0))\n",
    "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e885e15",
   "metadata": {},
   "source": [
    "Next we will be selecting the columns based on how they affect the p-value. We are the removing the column diagnosis because it is the column we are trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa73a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command lets us to vizualise which features were kept\n",
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now make a list of selected features \n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "\n",
    "print('Total features:{}'.format((X_train.shape[1])))\n",
    "print('Selected features:{}'.format(len(selected_feat)))\n",
    "print('Features with coefficients shrank to zero:{}'.format(np.sum(sel_.estimator_.coef_==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43593291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of features which coefficient was shrank to zero \n",
    "np.sum(sel_.estimator_.coef_==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the removed features \n",
    "removed_feats =X_train.columns[(sel_.estimator_.coef_==0).ravel().tolist()]\n",
    "removed_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f434cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e807a",
   "metadata": {},
   "source": [
    "## List of Features in all Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['maxtp', 'mintp', 'rain', 'people_vaccinated', 'total_boosters',\n",
    "       'congestion', 'C1_School closing', 'C2_Workplace closing',\n",
    "       'C3_Cancel public events', 'C4_Restrictions on gatherings',\n",
    "       'C5_Close public transport', 'C6_Stay at home requirements',\n",
    "       'C7_Restrictions on internal movement',\n",
    "       'C8_International travel controls', 'Retail and Recreation',\n",
    "       'Grocery and Pharmacy', 'Parks', 'Transit Stations', 'Workplaces',\n",
    "       'Residential', 'Daily_Confirmed', 'Wate Qty', 'Congestion+1',\n",
    "       'Congestion+2', 'Congestion+3', 'Congestion+4', 'Congestion+5',\n",
    "       'Congestion+6', 'Congestion+7', 'Holiday_0', 'Holiday_1', 'Season_1',\n",
    "       'Season_2', 'Season_3', 'Season_4', 'Day_0', 'Day_1', 'Day_2', 'Day_3',\n",
    "       'Day_4', 'Day_5', 'Day_6']\n",
    "RF_Features = ['Congestion+7',\n",
    "              'Retail and Recreation',\n",
    "              'Workplaces',\n",
    "              'Day_6', \n",
    "              'Congestion+1', \n",
    "               'Wate Qty',\n",
    "              'Residential', \n",
    "              'Holiday_0',\n",
    "               'Grocery and Pharmacy',\n",
    "               'Holiday_1', \n",
    "               'Parks',\n",
    "               'Season_1',\n",
    "               'Congestion+6',\n",
    "               'Congestion+3',\n",
    "               'C1_School closing', \n",
    "               'Congestion+3']\n",
    "lg_features = ['maxtp', 'mintp', 'rain', 'people_vaccinated',\n",
    "       'congestion', 'C1_School closing',\n",
    "       'C3_Cancel public events',\n",
    "       'C5_Close public transport', 'C6_Stay at home requirements',\n",
    "       'C7_Restrictions on internal movement',\n",
    "       'C8_International travel controls', 'Retail and Recreation',\n",
    "       'Grocery and Pharmacy', 'Parks', 'Transit Stations', 'Workplaces',\n",
    "       'Residential', 'Daily_Confirmed', 'Wate Qty', 'Congestion+1',\n",
    "       'Congestion+2', 'Congestion+3', 'Congestion+4', 'Congestion+5',\n",
    "       'Congestion+6', 'Congestion+7','Season_1',\n",
    "       'Season_2', 'Season_3', 'Season_4', 'Day_0', 'Day_1',\n",
    "       'Day_4', 'Day_5', 'Day_6'] \n",
    "lasso_Features = ['maxtp', 'mintp', 'rain', 'people_vaccinated', \n",
    "       'congestion', 'C1_School closing', 'C2_Workplace closing',\n",
    "       'C3_Cancel public events', 'C4_Restrictions on gatherings',\n",
    "       'C5_Close public transport', 'C6_Stay at home requirements',\n",
    "       'C7_Restrictions on internal movement',\n",
    "       'C8_International travel controls',\n",
    "       'Grocery and Pharmacy','Transit Stations', 'Workplaces',\n",
    "       'Residential', 'Daily_Confirmed', 'Wate Qty', 'Congestion+1',\n",
    "       'Congestion+2','Congestion+4', 'Congestion+5',\n",
    "       'Congestion+6', 'Congestion+7', 'Holiday_0','Season_1',\n",
    "       'Season_2', 'Season_3', 'Season_4', 'Day_0', 'Day_1','Day_3',\n",
    "       'Day_4', 'Day_5', 'Day_6']\n",
    "pearson_Features=['people_vaccinated','C1_School closing', \n",
    "                 'Retail and Recreation', 'Grocery and Pharmacy', 'Transit Stations', \n",
    "                 'Congestion+1', 'Congestion+2', 'Congestion+6', 'Congestion+7'] \n",
    "len (all_features), len(RF_Features), len(lg_features), len(lasso_Features), len(pearson_Features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
